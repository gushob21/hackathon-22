{
  "pipelineSpec": {
    "components": {
      "comp-endpoint-create": {
        "executorLabel": "exec-endpoint-create",
        "inputDefinitions": {
          "parameters": {
            "display_name": {
              "type": "STRING"
            },
            "location": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "endpoint": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-export-bqml-to-tf": {
        "executorLabel": "exec-export-bqml-to-tf",
        "inputDefinitions": {
          "artifacts": {
            "bqml_model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "bq_location": {
              "type": "STRING"
            },
            "export_location": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "tf_model": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-import-data-to-bigquery": {
        "executorLabel": "exec-import-data-to-bigquery",
        "inputDefinitions": {
          "parameters": {
            "bq_dataset": {
              "type": "STRING"
            },
            "bq_location": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "table_name_prefix": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "raw_dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-model-deploy": {
        "executorLabel": "exec-model-deploy",
        "inputDefinitions": {
          "artifacts": {
            "endpoint": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            },
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "deployed_model_display_name": {
              "type": "STRING"
            },
            "location": {
              "type": "STRING"
            },
            "machine_type": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "endpoint": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-model-upload": {
        "executorLabel": "exec-model-upload",
        "inputDefinitions": {
          "parameters": {
            "artifact_uri": {
              "type": "STRING"
            },
            "display_name": {
              "type": "STRING"
            },
            "location": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "serving_container_image_uri": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "model": {
              "artifactType": {
                "schemaTitle": "system.Model",
                "schemaVersion": "0.0.1"
              }
            }
          }
        }
      },
      "comp-split-datasets": {
        "executorLabel": "exec-split-datasets",
        "inputDefinitions": {
          "artifacts": {
            "raw_dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "bq_dataset": {
              "type": "STRING"
            },
            "bq_location": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "test_dataset_folder": {
              "type": "STRING"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "bqml_dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "dataset_uri": {
              "type": "STRING"
            },
            "test_dataset_uri": {
              "type": "STRING"
            },
            "test_features_jsonl_filenames": {
              "type": "STRING"
            },
            "test_labels_csv_filename": {
              "type": "STRING"
            },
            "train_dataset_uri": {
              "type": "STRING"
            },
            "validate_dataset_uri": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-train-bqml-model": {
        "executorLabel": "exec-train-bqml-model",
        "inputDefinitions": {
          "artifacts": {
            "dataset": {
              "artifactType": {
                "schemaTitle": "system.Dataset",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "bq_location": {
              "type": "STRING"
            },
            "model_name": {
              "type": "STRING"
            },
            "num_trials": {
              "type": "INT"
            }
          }
        },
        "outputDefinitions": {
          "artifacts": {
            "bqml_model": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          },
          "parameters": {
            "query": {
              "type": "STRING"
            }
          }
        }
      },
      "comp-validate-infra": {
        "executorLabel": "exec-validate-infra",
        "inputDefinitions": {
          "artifacts": {
            "endpoint": {
              "artifactType": {
                "schemaTitle": "system.Artifact",
                "schemaVersion": "0.0.1"
              }
            }
          }
        },
        "outputDefinitions": {
          "parameters": {
            "instance": {
              "type": "STRING"
            },
            "prediction": {
              "type": "DOUBLE"
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-endpoint-create": {
          "container": {
            "args": [
              "--method.project",
              "{{$.inputs.parameters['project']}}",
              "--method.location",
              "{{$.inputs.parameters['location']}}",
              "--method.display_name",
              "{{$.inputs.parameters['display_name']}}",
              "--executor_input",
              "{{$}}",
              "--resource_name_output_artifact_uri",
              "{{$.outputs.artifacts['endpoint'].uri}}"
            ],
            "command": [
              "python3",
              "-m",
              "google_cloud_pipeline_components.remote.aiplatform.remote_runner",
              "--cls_name",
              "Endpoint",
              "--method_name",
              "create"
            ],
            "image": "gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7"
          }
        },
        "exec-export-bqml-to-tf": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "export_bqml_to_tf"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'kfp==1.8.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'kfp==1.8.2' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef export_bqml_to_tf(\n    project: str,\n    export_location: str,\n    bqml_model: Input[Model],\n    tf_model: Output[Artifact],\n    bq_location: str,\n):\n    from google.cloud import bigquery\n\n    bqml_table_name = bqml_model.uri.split(\"/\")[-1]\n    query = f\"\"\"\n     EXPORT MODEL `{bqml_table_name}`\n    OPTIONS(URI = '{export_location}')\n\n    \"\"\"\n    client = bigquery.Client(project=project, location=bq_location)\n    query_job = client.query(query)\n    query_job.result()\n\n    tf_model.uri = export_location\n    print(\"tf_model.uri :%s\"%export_location)\n\n"
            ],
            "image": "python:3.9"
          }
        },
        "exec-import-data-to-bigquery": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "import_data_to_bigquery"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'kfp==1.8.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'kfp==1.8.2' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef import_data_to_bigquery(\n    project: str,\n    bq_location: str,\n    bq_dataset: str,\n    raw_dataset: Output[Dataset],\n    table_name_prefix: str = \"taxis\",\n):\n    from google.cloud import bigquery\n\n    # Construct a BigQuery client object.\n    client = bigquery.Client(project=project, location=bq_location)\n\n    def create_dataset_if_not_exist(bq_dataset_id, bq_location):\n        print(\n            \"Checking for existence of bq dataset. If it does not exist, it creates one\"\n        )\n        dataset = bigquery.Dataset(bq_dataset_id)\n        dataset.location = bq_location\n        dataset = client.create_dataset(dataset, exists_ok=True, timeout=300)\n        print(f\"Created dataset {dataset.full_dataset_id} @ {dataset.location}\")\n\n    def import_dataset(table_name_dataset):\n        training_dataset_table_name = f\"{project}.{bq_dataset}.{table_name_dataset}\"\n        query = f\"\"\"\n        CREATE OR REPLACE TABLE\n            `{training_dataset_table_name}`\n           AS\n        SELECT\n          CASE(ABS(MOD(FARM_FINGERPRINT(TO_JSON_STRING(f)), 10)))\n            WHEN 9 THEN 'TEST'\n            WHEN 8 THEN 'VALIDATE'\n            ELSE 'TRAIN' END AS split_col,\n          pickup_longitude,\n          pickup_latitude,\n          dropoff_longitude,\n          dropoff_latitude,\n          total_amount\n        FROM\n          `nyc-tlc.yellow.trips` f\n        LIMIT 10000\n        \"\"\"\n        print(\"Importing the dataset\")\n        query_job = client.query(query)  # Make an API request.\n        query_job.result()\n        print(query.replace(\"\\n\", \" \"))\n        return training_dataset_table_name\n\n    bq_dataset_id = f\"{project}.{bq_dataset}\"\n    create_dataset_if_not_exist(bq_dataset_id, bq_location)\n\n    table_name_dataset = \"dataset\"\n    dataset_uri = import_dataset(table_name_dataset)\n\n    raw_dataset.uri = dataset_uri\n\n"
            ],
            "image": "python:3.9"
          }
        },
        "exec-model-deploy": {
          "container": {
            "args": [
              "--init.project",
              "{{$.inputs.parameters['project']}}",
              "--init.location",
              "{{$.inputs.parameters['location']}}",
              "--init.model_name",
              "{{$.inputs.artifacts['model'].uri}}",
              "--method.endpoint",
              "{{$.inputs.artifacts['endpoint'].uri}}",
              "--method.deployed_model_display_name",
              "{{$.inputs.parameters['deployed_model_display_name']}}",
              "--method.machine_type",
              "{{$.inputs.parameters['machine_type']}}",
              "--executor_input",
              "{{$}}",
              "--resource_name_output_artifact_uri",
              "{{$.outputs.artifacts['endpoint'].uri}}"
            ],
            "command": [
              "python3",
              "-m",
              "google_cloud_pipeline_components.remote.aiplatform.remote_runner",
              "--cls_name",
              "Model",
              "--method_name",
              "deploy"
            ],
            "image": "gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7"
          }
        },
        "exec-model-upload": {
          "container": {
            "args": [
              "--method.project",
              "{{$.inputs.parameters['project']}}",
              "--method.location",
              "{{$.inputs.parameters['location']}}",
              "--method.display_name",
              "{{$.inputs.parameters['display_name']}}",
              "--method.serving_container_image_uri",
              "{{$.inputs.parameters['serving_container_image_uri']}}",
              "--method.artifact_uri",
              "{{$.inputs.parameters['artifact_uri']}}",
              "--executor_input",
              "{{$}}",
              "--resource_name_output_artifact_uri",
              "{{$.outputs.artifacts['model'].uri}}"
            ],
            "command": [
              "python3",
              "-m",
              "google_cloud_pipeline_components.remote.aiplatform.remote_runner",
              "--cls_name",
              "Model",
              "--method_name",
              "upload"
            ],
            "image": "gcr.io/ml-pipeline/google-cloud-pipeline-components:0.1.7"
          }
        },
        "exec-split-datasets": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "split_datasets"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'pandas' 'pyarrow' 'fsspec' 'gcsfs' 'kfp==1.8.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'pandas' 'pyarrow' 'fsspec' 'gcsfs' 'kfp==1.8.2' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef split_datasets(\n    project: str,\n    bq_dataset: str,\n    raw_dataset: Input[Dataset],\n    bqml_dataset: Output[Dataset],\n    test_dataset_folder: str,\n    bq_location: str,\n) -> NamedTuple(\n    \"bqml_split\",\n    [\n        (\"dataset_uri\", str),\n        (\"test_features_jsonl_filenames\", list),\n        (\"test_labels_csv_filename\", str),\n        (\"train_dataset_uri\", str),\n        (\"test_dataset_uri\", str),\n        (\"validate_dataset_uri\", str),\n    ],\n):\n    from collections import namedtuple\n\n    import gcsfs\n    from google.cloud import bigquery\n\n    client = bigquery.Client(project=project, location=bq_location)\n\n    def create_separate_tables(splits, training_dataset_table_name):\n        output = {}\n        for s in splits:\n            destination_table_name = f\"taxis_{s}\"\n            query = f\"\"\"\n            CREATE OR REPLACE TABLE `{project}.{bq_dataset}.{destination_table_name}` AS SELECT\n          pickup_longitude,\n          pickup_latitude,\n          dropoff_longitude,\n          dropoff_latitude,\n          total_amount\n          FROM `{training_dataset_table_name}`  f\n          WHERE \n          f.split_col = '{s}'\n          \"\"\"\n            print(f\"Creating table for {s} --> {destination_table_name}\")\n            print(query.replace(\"\\n\", \" \"))\n            output[s] = destination_table_name\n            query_job = client.query(query)  # Make an API request.\n            query_job.result()\n\n        print(output)\n        return output\n\n    def create_bqml_dataset(training_dataset_table_name):\n        bqml_dataset_table_name = \"dataset_bqml\"\n\n        query = f\"\"\"\n        CREATE OR REPLACE TABLE\n          `{project}.{bq_dataset}.{bqml_dataset_table_name}`  AS\n        SELECT\n          pickup_longitude,\n          pickup_latitude,\n          dropoff_longitude,\n          dropoff_latitude,\n          total_amount,\n          CASE(split_col)\n            WHEN 'VALIDATE' THEN 'EVAL'\n            WHEN 'TRAIN' THEN 'TRAIN'\n            WHEN 'TEST' THEN 'TEST'\n        END\n          AS split_col\n        FROM\n          `{project}.{bq_dataset}.{training_dataset_table_name}`  f\n        WHERE\n          split_col IN ('VALIDATE',\n            'TRAIN')\n        \"\"\"\n\n        # print(query)\n        query_job = client.query(query)  # Make an API request.\n        query_job.result()\n        return bqml_dataset_table_name\n\n    def export_test_features_to_gcs(bq_test_table_name, gcs_export_path_prefix):\n        query_string = f\"\"\"\n        SELECT\n          pickup_longitude,\n          pickup_latitude,\n          dropoff_longitude,\n          dropoff_latitude,\n          total_amount\n        FROM `{project}.{bq_dataset}.{bq_test_table_name}`  f\n        \"\"\"\n        print(f\"Exporting test dataset {project}.{bq_dataset}.{bq_test_table_name}\")\n        print(query_string.replace(\"\\n\", \" \"))\n        dataframe = (\n            client.query(query_string)\n            .result()\n            .to_dataframe(\n                # Optionally, explicitly request to use the BigQuery Storage API. As of\n                # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n                # API is used by default.\n                create_bqstorage_client=True,\n            )\n        )\n\n        test_labels_csv_filename = f\"{gcs_export_path_prefix}/test_labels.csv\"\n        labels = dataframe[\"total_amount\"]\n        print(f\"Exporting test labels into {test_labels_csv_filename}\")\n        labels.to_csv(test_labels_csv_filename, index=False, header=True)\n\n        test_features_jsonl_filename = f\"{gcs_export_path_prefix}/test_features.jsonl\"\n        features = dataframe.drop(columns=[\"total_amount\"])\n        jsonl = features.to_json(orient=\"records\", lines=True)\n        gcs = gcsfs.GCSFileSystem()\n        with gcs.open(test_features_jsonl_filename, \"w\") as text_file:\n            text_file.write(jsonl)\n\n        print(f\"Exporting test labels into {test_features_jsonl_filename}\")\n        return test_features_jsonl_filename, test_labels_csv_filename\n\n    table_name_dataset = \"dataset\"\n    dataset_uri = raw_dataset.uri\n    splits = [\"TRAIN\", \"VALIDATE\", \"TEST\"]\n    table_names_dict = create_separate_tables(splits, dataset_uri)\n    bqml_dataset_table_name = create_bqml_dataset(table_name_dataset)\n    test_table_name = table_names_dict[\"TEST\"]\n    (\n        test_features_jsonl_filename,\n        test_labels_csv_filename,\n    ) = export_test_features_to_gcs(test_table_name, test_dataset_folder)\n    dataset_uri = \"bq://\" + dataset_uri\n    train_dataset_uri = f\"bq://{project}.{bq_dataset}.{table_names_dict['TRAIN']}\"\n    test_dataset_uri = f\"bq://{project}.{bq_dataset}.{table_names_dict['TEST']}\"\n    validate_dataset_uri = f\"bq://{project}.{bq_dataset}.{table_names_dict['VALIDATE']}\"\n    bqml_dataset_uri = f\"bq://{project}.{bq_dataset}.{bqml_dataset_table_name}\"\n\n    print(f\"dataset: {dataset_uri}\")\n    print(f\"training: {train_dataset_uri}\")\n    print(f\"test: {test_dataset_uri}\")\n    print(f\"validation: {validate_dataset_uri}\")\n\n    bqml_dataset.uri = bqml_dataset_uri\n    print(bqml_dataset_uri)\n\n    result_tuple = namedtuple(\n        \"bqml_split\",\n        [\n            \"dataset_uri\",\n            \"test_features_jsonl_filenames\",\n            \"test_labels_csv_filename\",\n            \"train_dataset_uri\",\n            \"test_dataset_uri\",\n            \"validate_dataset_uri\",\n        ],\n    )\n\n    return result_tuple(\n        dataset_uri=str(dataset_uri),\n        test_features_jsonl_filenames=[test_features_jsonl_filename],\n        test_labels_csv_filename=test_labels_csv_filename,\n        train_dataset_uri=train_dataset_uri,\n        test_dataset_uri=test_dataset_uri,\n        validate_dataset_uri=validate_dataset_uri,\n    )\n\n"
            ],
            "image": "python:3.9"
          }
        },
        "exec-train-bqml-model": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "train_bqml_model"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'kfp==1.8.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-bigquery' 'kfp==1.8.2' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef train_bqml_model(\n    dataset: Input[Dataset],\n    bqml_model: Output[Artifact],\n    bq_location: str,\n    model_name: str = \"linear_regression_model\",\n    num_trials: int = 4,\n) -> NamedTuple(\"bqml_training\", [(\"query\", str)]):\n    from collections import namedtuple\n\n    from google.cloud import bigquery\n\n    dataset_uri = dataset.uri\n    table_name = dataset_uri.split(\"bq://\")[-1]\n    print(table_name)\n    uri_parts = table_name.split(\".\")\n    print(uri_parts)\n    project = uri_parts[0]\n    bq_dataset = uri_parts[1]\n\n    client = bigquery.Client(project=project, location=bq_location)\n\n    model_table_name = f\"{project}.{bq_dataset}.{model_name}\"\n\n    model_options = \"\"\"OPTIONS\n      ( MODEL_TYPE='LINEAR_REG',\n        LS_INIT_LEARN_RATE=0.15,\n        L1_REG=1,\n        MAX_ITERATIONS=5,\n        DATA_SPLIT_COL='split_col',\n        DATA_SPLIT_METHOD='CUSTOM',\n        input_label_cols=['total_amount']\n\n    \"\"\"\n    if num_trials > 0:\n        model_options += f\"\"\", \n\n        NUM_TRIALS={num_trials},\n        HPARAM_TUNING_OBJECTIVES=['mean_squared_error']\"\"\"\n    model_options += \")\" \"\"\n\n    query = f\"\"\"\n    CREATE OR REPLACE MODEL\n      `{model_table_name}`\n      {model_options}\n     AS\n    SELECT\n      pickup_longitude,\n      pickup_latitude,\n      dropoff_longitude,\n      dropoff_latitude,\n      total_amount,\n      split_col\n    FROM\n      `{table_name}`;\n    \"\"\"\n\n    print(query.replace(\"\\n\", \" \"))\n    query_job = client.query(query)  # Make an API request.\n    print(query_job.job_id)\n    query_job.result()\n    bqml_model.uri = f\"bq://{model_table_name}\"\n    print(bqml_model)\n    print(f\"bq://{model_table_name}\")\n\n    result_tuple = namedtuple(\"bqml_training\", [\"query\"])\n\n    return result_tuple(query=str(query))\n\n"
            ],
            "image": "python:3.9"
          }
        },
        "exec-validate-infra": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "validate_infra"
            ],
            "command": [
              "sh",
              "-c",
              "(python3 -m ensurepip || python3 -m ensurepip --user) && (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.2' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet                 --no-warn-script-location 'google-cloud-aiplatform' 'kfp==1.8.2' --user) && \"$0\" \"$@\"",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef validate_infra(\n    endpoint: Input[Artifact],\n) -> NamedTuple(\n    \"validate_infrastructure_output\", [(\"instance\", str), (\"prediction\", float)]\n):\n    import json\n    from collections import namedtuple\n\n    from google.cloud import aiplatform\n    from google.protobuf import json_format\n    from google.protobuf.struct_pb2 import Value\n\n    def treat_uri(uri):\n        return uri[uri.find(\"projects/\") :]\n\n    def request_prediction(endp, instance):\n        instance = json_format.ParseDict(instance, Value())\n        instances = [instance]\n        parameters_dict = {}\n        parameters = json_format.ParseDict(parameters_dict, Value())\n        response = endp.predict(instances=instances, parameters=parameters)\n        print(\"deployed_model_id:\", response.deployed_model_id)\n        print(\"predictions: \", response.predictions)\n        # The predictions are a google.protobuf.Value representation of the model's predictions.\n        predictions = response.predictions\n\n        for pred in predictions:\n            if type(pred) is dict and \"value\" in pred.keys():\n                # AutoML predictions\n                prediction = pred[\"value\"]\n            elif type(pred) is list:\n                # BQML Predictions return different format\n                prediction = pred[0]\n            return prediction\n\n    endpoint_uri = endpoint.uri\n    treated_uri = treat_uri(endpoint_uri)\n\n    instance = {\n        \"pickup_longitude\":-74.002387,\n        \"pickup_latitude\":40.719832,\n        \"dropoff_longitude\":-74.00239,\n        \"dropoff_latitude\":40.719825\n    }\n    instance_json = json.dumps(instance)\n    print(\"Will use the following instance: \" + instance_json)\n\n    endpoint = aiplatform.Endpoint(treated_uri)\n    prediction = request_prediction(endpoint, instance)\n    result_tuple = namedtuple(\n        \"validate_infrastructure_output\", [\"instance\", \"prediction\"]\n    )\n\n    return result_tuple(instance=str(instance_json), prediction=float(prediction))\n\n"
            ],
            "image": "python:3.9"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "prediction"
    },
    "root": {
      "dag": {
        "tasks": {
          "endpoint-create": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-endpoint-create"
            },
            "dependentTasks": [
              "model-upload"
            ],
            "inputs": {
              "parameters": {
                "display_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "prediction_endpoint"
                    }
                  }
                },
                "location": {
                  "componentInputParameter": "region"
                },
                "project": {
                  "componentInputParameter": "project"
                }
              }
            },
            "taskInfo": {
              "name": "endpoint-create"
            }
          },
          "export-bqml-to-tf": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-export-bqml-to-tf"
            },
            "dependentTasks": [
              "train-bqml-model"
            ],
            "inputs": {
              "artifacts": {
                "bqml_model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "bqml_model",
                    "producerTask": "train-bqml-model"
                  }
                }
              },
              "parameters": {
                "bq_location": {
                  "componentInputParameter": "bq_location"
                },
                "export_location": {
                  "componentInputParameter": "bqml_model_export_location"
                },
                "project": {
                  "componentInputParameter": "project"
                }
              }
            },
            "taskInfo": {
              "name": "export-bqml-to-tf"
            }
          },
          "import-data-to-bigquery": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-import-data-to-bigquery"
            },
            "inputs": {
              "parameters": {
                "bq_dataset": {
                  "componentInputParameter": "bq_dataset"
                },
                "bq_location": {
                  "componentInputParameter": "bq_location"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "table_name_prefix": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "taxis"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "import-data-to-bigquery"
            }
          },
          "model-deploy": {
            "cachingOptions": {},
            "componentRef": {
              "name": "comp-model-deploy"
            },
            "dependentTasks": [
              "endpoint-create",
              "model-upload"
            ],
            "inputs": {
              "artifacts": {
                "endpoint": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "endpoint",
                    "producerTask": "endpoint-create"
                  }
                },
                "model": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "model",
                    "producerTask": "model-upload"
                  }
                }
              },
              "parameters": {
                "deployed_model_display_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "prediction_best"
                    }
                  }
                },
                "location": {
                  "componentInputParameter": "region"
                },
                "machine_type": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "n1-standard-2"
                    }
                  }
                },
                "project": {
                  "componentInputParameter": "project"
                }
              }
            },
            "taskInfo": {
              "name": "model-deploy"
            }
          },
          "model-upload": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-model-upload"
            },
            "dependentTasks": [
              "export-bqml-to-tf"
            ],
            "inputs": {
              "parameters": {
                "artifact_uri": {
                  "componentInputParameter": "bqml_model_export_location"
                },
                "display_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "prediction_bqml"
                    }
                  }
                },
                "location": {
                  "componentInputParameter": "region"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "serving_container_image_uri": {
                  "componentInputParameter": "bqml_serving_container_image_uri"
                }
              }
            },
            "taskInfo": {
              "name": "model-upload"
            }
          },
          "split-datasets": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-split-datasets"
            },
            "dependentTasks": [
              "import-data-to-bigquery"
            ],
            "inputs": {
              "artifacts": {
                "raw_dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "raw_dataset",
                    "producerTask": "import-data-to-bigquery"
                  }
                }
              },
              "parameters": {
                "bq_dataset": {
                  "componentInputParameter": "bq_dataset"
                },
                "bq_location": {
                  "componentInputParameter": "bq_location"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "test_dataset_folder": {
                  "componentInputParameter": "test_dataset_folder"
                }
              }
            },
            "taskInfo": {
              "name": "split-datasets"
            }
          },
          "train-bqml-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-train-bqml-model"
            },
            "dependentTasks": [
              "split-datasets"
            ],
            "inputs": {
              "artifacts": {
                "dataset": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "bqml_dataset",
                    "producerTask": "split-datasets"
                  }
                }
              },
              "parameters": {
                "bq_location": {
                  "componentInputParameter": "bq_location"
                },
                "model_name": {
                  "runtimeValue": {
                    "constantValue": {
                      "stringValue": "linear_regression_model"
                    }
                  }
                },
                "num_trials": {
                  "runtimeValue": {
                    "constantValue": {
                      "intValue": "4"
                    }
                  }
                }
              }
            },
            "taskInfo": {
              "name": "train-bqml-model"
            }
          },
          "validate-infra": {
            "cachingOptions": {},
            "componentRef": {
              "name": "comp-validate-infra"
            },
            "dependentTasks": [
              "model-deploy"
            ],
            "inputs": {
              "artifacts": {
                "endpoint": {
                  "taskOutputArtifact": {
                    "outputArtifactKey": "endpoint",
                    "producerTask": "model-deploy"
                  }
                }
              }
            },
            "taskInfo": {
              "name": "validate-infra"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "bq_dataset": {
            "type": "STRING"
          },
          "bq_location": {
            "type": "STRING"
          },
          "bqml_model_export_location": {
            "type": "STRING"
          },
          "bqml_serving_container_image_uri": {
            "type": "STRING"
          },
          "gcs_batch_prediction_output_prefix": {
            "type": "STRING"
          },
          "project": {
            "type": "STRING"
          },
          "region": {
            "type": "STRING"
          },
          "test_dataset_folder": {
            "type": "STRING"
          },
          "thresholds_dict_str": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.2"
  },
  "runtimeConfig": {}
}